Avant-Propos :

Conteneur : virtualisation de niveau systeme d'exploitation
Hyperviseur/VM : virtualisation au niveau materiel

Contrairement a une VM, un conteneur n'embarque pas d'OS complet

1. Conteneurs et le cas Docker
1.1 La conteneurisation

Dans une architecture a base de conteneurs :
- Le contenu du conteneur, cad le code et ses dependances (jusqu'a l'OS) est de la responsabilite du dev
- La gestion du conteneur et les dependances avec l'infra sont de la responsabilite de l'exploitant

Virtualisation materielle : chaque logiciel se trouve dans un sandox
- Poids d'une VM important
- Elle ne laisse pas a l'exploitant la possibilite de choisir librement les caracteristiques comme le stockage ou le nombre de CPU...

Architecture a base de conteneur : compromis
- Isolation presente
- Conteneur s'appuie sur le kernel de l'OS hote, il est donc leger. Un hote peut executer beaucoup plus de conteneurs que d'equivalent VM

Eventuellement, conteneurs dans une VM permet de se premunir des MAJ de l'OS hote qui pourraient impacter les conteneurs.
Il existe des projets visant a fournir des OS hotes minimaux qui se focalisent uniquement sur les problemes d'infra. Cela limite les risques d'attaques et de bug.

Docker apporte 2 avantages aux solutions a base de conteneurs :
- Possibilite de decrire formellement comment construire le conteneur
- Format d'image standardisee

1.2 Les fondations : Linux, cgroups et namespaces

Docker est une solution open-source de conteneur Linux.
Initialement, s'appuie sur LXC (Linux Containers) pour implementation, puis libcontainer (bibli bas niveau) puis runC, standard de l'OCI (Open Container Initiative).
Docker aujourd'hui construit au-dessus de containerd qui s'appuie sur runC.

Contaitneurs sont une techno liee au noyau Linux (Linux Kernel) et certains de ses services sont orchestree par containerd.

Depuis 2016, possibilite d'executer des conteneurs natif sous windows grace au portage de runC sur le noyau Windows.

Pour executer des conteneurs Linux sous Windows, on fait tourner une VM Hyper-V avec OS LinuxKit LCOW (Linux Containers On Windows) et le conteneur a l'interieur.
Idem sous Mac, on fait tourner une VM basee sur l'Hypervisor Framework Apple : Xhyve

CGroups : (Control Groups)
Permet de partitionner les ressources d'un hote pour controler la consommation des ressources process par process
Introduit la notion de controleur avec pour objectif de controler acces a une ressource pour une hierarchie de process

Namespaces : Permet de faire en sorte que les processus ne voient pas les ressources utilisees par d'autres.
Version amelioree de chroot : Le process aura l'impression d'etre a la racine du systeme. Namespace etend le concept a d'autres ressources (Com interprocess, Terminaux resaux, point de montage systeme etc...)

(!)
Un conteneur est un systeme de fichier sur lequel s'executent des process (de preference 1 par conteneur) de facon :
- contrainte : grace a cgroups qui specifie les limites en termes de ressources
- isolee : grace a namespaces qui fait en sorte que les conteneurs ne se voient pas les uns les autres

1.3 Les apports de Docker : Structure en couches, images, volumes et registery

Docker optimise la taille des conteneurs :
Construire un conteneur a la main : Operation fastidieuse et probleme de distribution et reutilisation
(!)
Par exemple stocker les fichiers specifiques au conteneur qui ne font pas partie de l'OS dans un repertoire
Apport essentiel de Docker : les images, qui sont une maniere de conditionner le contenu d'un conteneur en blocs reutilisables et echangeables.

Possible grace a l'union file system :
Chaque couche surcharge la precedente en y apportant de modifications et ajouts.
On a plusieurs couches successives qui sont autant de blocs reutilisables.

Docker Hub et registry :
Le registry est l'annuaire et le centre de stockage des images reutilisables.
Docker Hub est sa principale instanciation publique
Le registry Docker herberge les images de base de principaux systemes d'exploitation (Ubuntu, Debian ...) et de nombreux logiciels courants (bdd, serveurs d'appli etc...)
Le registry peut etre au choix :
- Le lieu de stockage d'images crees sur un hote par un dev (docker push)
- La source d'images a installer sur un ou plusieurs hotes (docker pull)
(!)
Certaines images peuvent rester privees et ne pas etre publiees sur un registry : ces images restent au niveau du cache de l'hote

Reutilisation des images de 2 manieres :
- A l'echelle d'un hote, via un cache local
- A l'echelle d'un registry, en offrant un moyen de partage d'images

Copy on write, persistance des volumes :

A un moment, l'image d'un conteneur va etre mise en route (execution de process qui consomment de la memoire, ecrire des donnees etc...)
Les donnes sont produites dans une couche au dessus de toutes les autres, la container layer.
Cette couche est modifiable contrairement aux couches d'image qui ne le sont pas.
Le Copy On Write : Lorsqu'une modification est demandee sur un element de l'image, le fichier original est copie te la nouvelle version surchage l'originale.
Le COW n'est utilise que lors d'une modification, sinon c'est la version originale de l'image qui est utilisee.
La couche du conteneur ne contient que le differentiel par rapport a l'image.
(!)
La maniere de gerer le COW et l'union des couches depend du storage driver. Docker est livre avec un driver par defaut adapte a l'OS.

Quand le conteneur s'arrete, la container layer est perdue. Pour conserver des donnees -> volumes.
Les volumes sont des espaces de donnees qui court-circuitent le system d'union file. Ils sont modifies directement et les donnees qui y sont inscrites survivent a l'arret du conteneur.
Ce sont des systemes de fichiers montes dans le conteneur :
(!)
- Sur un espace disque de l'hote gere par Docker
- Sur un repertoire de l'hote directement monte dans le conteneur

1.4 Les outils de l'ecosysteme des conteneurs :

Les moteurs :
Le moteur d'execution de conteneur (par exemple Docker Engine) offre des fonctionnalites de plus haut niveau par rappoort a Cgroups et Namespace :
- une CLI
- des API
- Capacite de nommer, decouvrir et gerer le cycle de vie des conteneurs
- La capacitee de creer des conteneurs a partir d'images ou de modeles

Il existe d'autres type de moteur que le Docker Engine :
- LXC sur lequel Docker s'appuyait avant la libcontainer
- Containerd, basee sur runC (composant de bas niveau destine a s'integrer dans des moteurs de plus haut niveau)
- Podman

Le standard OCI (Open Container Initiative) pour les images ou CRI (Container Runtime Interface) pour Kubernetes impose un standard qui assure portabilite entre les environnements et les moteurs.
Docker reste l'outil de reference pour les dev, mais n'est plus le leader cote serveur.

OS specialises :
Les conteneurs reutilisent le noyau de l'OS de l'hote sur lequel ils tournent.
Les containers OS sont des OS simplifies, plus performants et moins exposes aux risques de securite ou d'instabilite
Exemples :
- Fedora CoreOS pour Redhat
- LinuxKit qui permet de creer des distro Linux compactes (dont LCOW qu'utilise window au sein de sont hyper-v)
etc...

Pour Windows :
- Windows Server Core pour les hotes qui n'executent que des machines virtuelles ou des conteneurs
- Windows Nano Server pour l'image de base de conteneurs Windows

Outils d'orchestration :
Les bonnes pratiques en matiere d'architecture consistent a distribuer les processus dans plusieurs conteneurs.
(!)
Il faudra donc les associer, c'est la composition :
- Definir l'ordre de demarrage.
- Definier les systemes de fichier persistants (volumes)
- Definir les liens reseau que les conteneurs vont entretenir entre eux
On peut demarrer les conteneurs a la main avec un script qui execute des docker run, mais on ne peut pas distribuer la charge dans ce cas.
Il faut que le composition s'effectue en collaboration avec les outils de clustering reseau qui vont abolir les frontieres entre les differents hotes.
C'est l'orchestration : Composition + clustering

DCOS : Data Center OS
Solution de haut niveau pour orchestration. Le standard est Kubernetes.

2. Orchestration de conteneurs.
2.1 Automatiser la gestion de l'infra : du IaaS au CaaS

IaaS : Virtualisation d'infra
Les solutions IaaS offrent aux appli conditionnes sous forme d'images de machines virtuelles des services d'infrastructure : Puissance de calcul, stockage, services reseau, securitee.
Les solutions IaaS vont detecter les failles materielles et s'assurer que l'environnement d'exe est toujours actif.

En mode IaaS, le dev doit specifier ses besoin en matiere d'environnement d'exe :
Dialogue pousse entre le dev et l'exploitant.
Le dev specifie ses besoins (version java, bdd, server d'appli...) et l'exploitant les interprete.
Phase sensible et complexe.

Apres avoir produit et conditonne sont code (build et packaging) le dev donne son paquet logiciel a l'exploitant.
Il doit rester coherent avec l'archi de la solution.
La gestion de la solution de deploiement est la responsabilite de l'exploitant.

Iaas:
Apporte solution sur preparation environnement applicatif :
- Automatisation du provisionnement de l'infra. Tout se fait par config, si capactite dispo (Pas besoin pour client d'acheter des serveurs etc...)
- Maniere simple de monter en charge si l'appli le permet : On redimensionne l'environnement en ajoutant CPU, RAM etc...

Ne donne pas de solution pour :
- Deploiement des applis (Installation et mise en route une fois la VM cree)
- Description formelle des caracteristiques d'evolutivite et de resilience de l'appli a faire par le dev et l'execution en prod.

Apport du deploiement en CaaS :
Les phases de preparation de l'env et le deploiement sont indistinctes :
- L'image de conteneur inclue l'environnement d'exe (runtime) en meme temps que le code.
- Si usage Docker, via image, le paquet logiciel est exactement ce qui va etre deploye.
Il n'y a pas de retraitement de l'image par une solution tierce.
Comme un conteneur physique, l'exploitant est comme un transporteur : il choisit la maniere dont le conteneur va etre execute sans l'alterer.

De plus, les sulitions CaaS associent au deploiement des regles de gestion (sous forme de fichier YAML ou JSON).
Cette config va specifier de facon formelle les carac non fonctionnelles de l'archi : nombre d'instance, liens en conteneurs, regles de montee en charge et repartition...

Une appli doit etre developpee des le debut pour etre container-ready en revanche

Carac communes des solutions CaaS :
- Moteur de de conteneurs : Conteneurd en general (ou Docker Engine)
- Fonctions de clustering et d'orchestration
- Principe de gestion automatisee de l'infra (homeostasie)

Regulation homeostatique : toutes les solutions CaaS ont ces composants en commun avec pour but :
- Surveiller etat du systeme
- Detecter les ecarts par rapport au regles de gestion programmees
- Prendre des mesures pour ramener l'equilibre
- Prevenir l'exploitant en cas d'echec.

System de regulation:
- Controleur qui analyse l'etat de l'infra via les donnees remontees par les agents. Il donne des ordres aux agents.
- Agents qui collectent des infos sur l'etat des noeuds (le feedback) et servent de relais au controleur pour executer les actions correctrices.
- Une interface d'entree de regles de gestion : une CLI generalement (entree directe ou fichier conf)

L'exploitant programme les regles de gestion (sur la base de proposition du dev)
Ces regles de gestion persistent pendant tout le cycle de l'appli.

DCOS :
Les conteneurs et les Caas sont au coeur des DCOS mais n'en sont qu'une compostante.
Les DCOS doivent etre capables de gerer differents types de ressources et pas juste de conteneurs

2.2 Les solutions CaaS

Kubernetes :
Projet Open Source initie par Google.
Pour info, la plupart des technos de base des conteneurs (Cgroups et Namespaces) ont ete elaborees par des ingenieurs Google.
Kubernetes gere par la Linux Foundation

Archi Kubernetes :
- Controleur central : Kubernetes Control Plane. Peut stocker sa conf dans un cluster etcd.
- Des nodes : Hebergent les agents Kubernetes, les kubelets, et les conteneurs organises en pod.
Les kubelets sont les agents qui controlent les conteneurs organises en pod. Ils surveillent leur etat en utilisant cAdvisor qui est en lien avec le moteur de conteneur.
Le node contient egalement un kube-proxy : proxy repartiteur de charge (load balancer) pour les services offerst par les pods, uniquement au sein d'un cluster Kubernetes.

Le Kubernet Controle Pane subdivise en :
- Serveur API, utilise par Kubctl, la CLI qui permet de piloter les composants de l'archi
- Le Scheduler : pour provisionner de nouveaux pools de conteneurs sur les noeuds
- Le Controller Manager : Execute les boucles de controle

Nodes, pods et conteneurs :
Un node correspond en general a un hote physique ou virtuel
Un pod est un groupe de conteneurs toujours colocalises et provisionnes ensembles. Ils sont lies les uns aux autres et offrent une instance de micro-service
(!)
Tous les conteneurs d'un pod se trouvent dans une meme machine logique :
- Partagent les meme volumes
- Peuvent interagir en utilisant le nom de domaine localhost ce qui simplifie les interacitons
Chaque pod est associe a une IP unique. L'espace d'adressage a l'interieur d'un cluster est plat (pod peuvent se parler sans recours a la NAT)

Un service est un ensemble de pods associes a des regles d'acces, de replication et de repartition de charges specifiques
La notion de service interne au cluster : le kube-proxy permet a un pod front-end de trouver un pod back-end en utilisant des regles de repartition de charge.
En revanche, si un utilisateur exterieur veut acceder au front-end, on utilise un external load-balancer qui sera associe a une IP publique et offrira chiffrement SSl, load balancing niveau 7, affinite session etc...
L'implementation open source de l'external load balancer est basee sur NGINX

Toute solution d'orchestration de conteneur se doit de supporter Kubernetes

Modele Docker Entreprise : echec commercial
- Docker Compose :  encore beaucoup utilise par les dev comme outils de composition de conteneurs
- Docker Classic Swarm : Offre de clustering concurrente de Kubernetes. Transformait plusieurs machines en 1 seul hote.
- Docker Trusted Registry : Stockage des images conteneurs
- Docker UCP (Universal Control Pane) : Centre de control Datacenter

Une des strategies de swarm etait spread : lors de la creation d'un certain nombre de conteneurs, la strategie s'assurait que les creations etaient distribuees uniformement sur chaque noeud d'un cluster

DCOS :
Apache Mesos est a l'origine.
Concept de Framework, qui permet de se brancher sur diverses solution de controle, dont Kub.
Architecture : des mesos master (eventuellement dupliques, comme des master nodes) et des mesos slaves qui hebergent les agents emis depuis le master et fournir des infos
Mesos peut utiliser d'autres techo de deploiement et d'exe.

Openshift de Red Hat : Solution de reference de Kubernetes pour une installation privee
Contruite en integrant les produits CoreOS

Nomad de HashiCorp :
Etend la gestion de process distribues au dela des conteneur (a la maniere de Mesos)
Permet transition entre ancien monde et celui des conteneurs et du multi-conteneur mono-hote vers le multi-multi

Les 3 plus grosses offres de cloud container service :
- Google Kubernetes Engine
- Azure Kubernets Service
- Amazon ECS

Ansible, Chef, Puppet : lien avec Docker et Caas

Les solutions CaaS sont nouveaute sur marche gestion d'infra. La plupart des service IT doivent composer avec un existant qui a large panel de techno.
Le but de ces solutions est d'unifier la gestion de configuration d'infra informatiques.
Elle se basent sur un DSL (Domain Specific Language) pour declarer la conf cible a atteindre.
Ces solutions visent a remplacer les nombreux scripts shell par une bibliotheque d'actions standardisees.
Cela permet de s'abstraire des evolutions techno. et surtout de simplifier l'elaboration de procedures de conf independantes des environnements.

Exemple : Ansible de Red Hat
Uniquement besoin du logiciel sur la machine de controle, pas besoin d'agents sur les machines qui doivent etre config : uniquement SSH et python
Playbook : descripteurs de config. Decrit l'etat souhaite pour un ou plusieurs hotes
Inventory : liste des hotes cibles, qui peuvent etre machines virtuelles
Les hotes cibles sont organises en groupes, ce qui permet de lancer des actions de masse

Playbook : par exemple au format YAML. C'est une description d'un etat souhaite, pas une liste de commandes.
Ansible collecte, avant d'effectuer des actions, des infos relatives a l'environnement de la machine (les facts)

Lien avec Docker et les solutions CaaS :
Comme les Caas, Ansible fonctionne en comparant une etat actuel avec un etat cible.
La difference est que la comparaison d'etat n'est pas permanente : on veut juste configurer un systeme et non pas le gerer en temps reel.
Les solutions CaaS et les gestion de conf type Ansible sont donc complementaires.
Par exemple Ansible va permettre installation et config des agents CaaS (ex: Kublets) sur les hotes
Ansible dispose d'un playbook docker par ex.
Ansible va gerer cycle de vie du conteneur, depuis chargement image jusqu'a creation et demarrage

3. Prise en main
3.2 Installation Docker

Docker Desktop :
- Docker Engine : Deamon et client docker
- Docker Compose
- Kubernetes monoposte

Une VM est cree qui fait tourner le deamon docker Linux qui peut etre controle :
- Via le client docker
- Via des requetes HTTP (API REST)

3.3 Premier conteneur
On peut interagir avec le daemon docker :
- Interface graphique sous Windows/Macos
- Ligne de commande Docker
- Appels HTTP via l'API Docker Remote

Client Docker :

Socket : ensemble normalise de fonctions de com. Permettent a une appli de se brancher a un reseau et communiquer avec une autre appli
Socket Unix : Moyen de communication inter-processus utilisant le system de fichier comme espace de nommage. Plus facile qu'avec des simples pipes dans le cas de plusieurs client accedant a un meme service

Le deamon docker ecoute sur un socket Unix a l'addresse /var/run/docker.socket.
Le client Docker utilise HTTP pour envoyer des commandes a ce socket qui sont transmises ensuite au deamon via HTTP

Socat utile pour lire les trames HTTP d'envoi.

Le client et le deamon Docker ont besoin de tourner avec les droits root pour monter des volumes par exemple. Les utilisateurs faisant partie du groupe docker pourront utiliser docker sans la commande sudo

Le deamon expose l'integralite de ses methodes via l'API Docker Remote. On peut l'appeler via curl ou wget.
Il faut pour cela ajouter un autre socket de connexion TCP que le deamon docker va ecouter en plus du socket unix

Fichier de conf pour modifier les parametres de demarrage du deamon :
/usr/lib/systemd/system/docker.service

4.Conteneurs et images
4.1 Cycle de vie du conteneur

create
start
stop : sigterm puis sigkill si besoin
kill : sigkill
rm
run = create + start

l'UUID court ou le nom peuvent etre utilises pour travailler sur un conteneur

docker stop :
L'image plus la container layer (couche persistance read/write) sont toujours presentes

4.2 Acceder au conteneur et modif ses donnees

Connexion mode terminal :
docker exec -t -i nom_conteneur /bin/bash
Le nom de l'hote sera l'UUID court du conteneur

Volumes :
Un moyen de Docker pour gerer la persistance des donnes au sein des conteneurs

Pour ajouter un volume simplement :
-v chemin_absolu_dossier_dans_conteneur
docker inspect pour voir ou il est monte sur l'hote
Pb :
- Besoin privileges etendu (root) pour acceder donnees sur hote
- Destruction/Creation Conteneur va entrainer allocation nouveau volume. Volume precedent sera orphelin

Monter un repertoire de l'hote dans le conteneur :
-v repertoire_hote:repertoire_conteneur
Possibilite de monter en lecture seule avec :ro

Config de ports IP :
-p pour preciser
-P pour que Docker choisisse des ports libre au hasard sur la machine hote

4.3 Contruire image docker originale

docker images pour lister les images presentes sur la machine
docker rmi pour supprimer une image

Images sans nom sont des images intermediaires

Recuperer une image a partir du docker hub :
docker pull img_name:tag

Creer une image a partir d'un contenuer :
docker commit nom_conteneur tag_image

4.4 Dockerfile
Permet de regler le probleme du processus de creation de l'image qui n'est pas normalisee

Dockerfile : creation d'images de maniere formelle

docker build -t tag_image

Pour heriter d'une image :
FROM img:tag

Pour ajouter un fichier :
COPY fichier_hote fichier_conteneur
Celui ci ne modifiera pas l'image de base, via l'Union File System, il sera pris en compte a la place
Cela constituera une couche en plus de l'UFS (cad une image intermediaire)

Image finale est constituee de serier d'images originales ou heritees.
docker history pour visualiser ensembles des couche d'une image

5. Apprendre Docker
5.1 Intro CLI docker

Variables d'env Docker :
Modifie le comportement des commandes docker.
ex : DOCKER_CONFIG qui donne l'emplacement du fichier de config.
Possibilite de definir un fichier de config perso

Option des commandes :
Si booleen non precise, il est a true

Bonne pratique : utiliser = que pour les options de type booleen

5.2 Commandes systeme
Commandes relatives au Docker Engine : pilotage ou obtention d'infos

dockerd : controle le daemon Docker
Il est demarre automatiquement

docker info : visualiser infos sur config docker
docker version : version client (cli) et serveur (deamon)
docker stats : comme un top sous linux, donne infos sur conteneurs executes
-a pour tous les conteneurs meme arretes, --no-stream pour un snapshot
docker ps : liste les conteneurs actifs
-a pour tous, -q pour quiet, --format ou --filter pour des options affichage
docker events : afficher les evenements qui se produisent sur le bus d'evenement docker
A la maniere d'un cat -f
docker inspect : recuperer sous former json les metadonnes d'un objet docker (image, conteneur ...)
docker df : obtenir les infos de l'espace disque utilise par le deamon docker
docker system prune / docker image prune : supprimer les conteneurs et reseaux non utilisee
supprimer egalement les images sans nom (dangling)
-a pour supprimer images non utilisees
--volumes pour supprimer volumes non attaches a des conteneurs

5.3 Cycle de vie conteneurs

docker start/stop/kill/restart/pause/unpause/rm
(!)
docker wait : bloque l'invit de commande tant que le conteneur passe en parametre n'est pas arrete
docker update : Modifier les parametres d'un conteneur demarre. Modification uniquement des ressoures allouees au conteneur (cpu, memoire etc...)
docker create/run :
Nombreux parametres :
- Controle ressoures
- Controle volumes
- Entry Point
- Privileges

5.4 Interractions avec conteneurs demarres

docker logs : afficher les logs du conteneur
Par defaut, docker mets a la dispo du log tout ce qui est ecrit dans STDOUT par process racine
--follow ou -f pour avoir affichage en continu
--tail X pour avoir uneiquement les X dernieres lignes de log
docker exec : executer une commande a l'interieur d'un conteneur demarre
possibilite de lancer sans -t -i pour faire des commands en mode non interractif
docker attach : attacher a un conteneur demarre pour visualiser les evenements
--sig-proxy=false permet de ne pas relayer les signaux (et donc de quitter le attach avec un Ctrl-C)
docker rename : renommer un conteneur
docker cp : copier des fichier entre un conteneur demarre et le systeme de fichier de l'hote
docker diff : visualiser les changement effectues sur les fichier d'un conteneur
A : ajout, C: changes, D : deletions
docker top : afficher le resultat de top dans le conteneur
docker export : export l'ensemble du systeme de fichiers d'un conteneur dans un fichier tar
docker port : visualiser les ports exposes d'un conteneur

5.5 Commandes relatives aux images

docker build : construire une image a partir d'un dockerfile
-t pour difnir un tag d'image, cad son nom
-f pour specifier un dockerfile
--rm pour effacer les images intermediaires

docker commit : creer une image a partir d'un conteneur demarre
docker history : visualiser les differentes couches d'une image et les instructions dockerfile associees
docker images : lister les images du cache local
-a pour avoir les images intermediaires
docker rmi : supprimer une image du cache local
docker save/load : importer des images depuis le cache local ou les exporter vers le cache local
docker import : importer un system de fichier d'un conteneur (apres un export)

5.6 Interractions avec le registry
docker login/logout
docker push/pull
docker search : chercher avec le nom de l'image
--filter "is-official=true"
docker tag : donner un nom alternatif a une image
rmi sur ce nouveau nom effacera uniquement l'alias et non l'image
alias lastest pointe toujours sur la derniere version

5.7 Reseau et volumes :
(voir tableau)

6. Les instruction dockerfile
6.1 Les modeles d'instructions

Plusieurs modeles possibles, dont en general :
- 1 au format terminal
- 1 au format execution

Format Terminal :
CMD <command>
S'execute au travers d'un terminal applicatif via /bin/sh -c <command>
Plus lisible que le format Execution
/bin/sh doit etre disponible dans l'image

Attention :
(!)
- Le PID du process demarre par le point d'entree du conteneur a le PID 1
- Lors d'un docker stop, seul le process de PID 1 est arrete proprement par un SIGTERM, les autres prennent un SIGKILL apres 10s
- Lorsque /bin/sh recoit un signal pour s'arreter, il ne le transmet pas a ses enfants

Format Execution :
CMD ["executable", "param1", "param2"]
Permet executer une commande sans intermediaire

Le format terminal etant plus lisible, on va l'utiliser si :
- L'image contient /bin/sh
- Il n'y a pas de process supplementaire qui necessite un arret propre

Recap :
- Test : Terminal
- Commande qui s'execute directement (ls, mkdir etc...) : Terminal
- Commande lancant un process : Exe
- Autres : Exe

Pour faire un commentaire, on utilise le prefixe "#"

6.2 Les instructions

FROM :
Specifie l'image docker parente a utiliser
Possibilite de specifier le tag ou le digest (par defaut, la commande utilise le tag latest)
FROM est la seule instruciton obligatoire d'un Dockerfile
Elle doit etre placee en debut de fichier
Attention, un Dockerfile peut avoir plusieurs instruction FROM, mais cela creera plusieurs images.
C'est en revanche mauvaise idee (impossible de specifier nom de l'image cible etc...)

2 bonnes pratiques :
- Un fichier dockerfile contient exactement une instruction FROM sauf en cas de constrution multi-etages
- Dans l'instruction FROM, toujours specifier la version de l'image source

RUN :
Executer des commandes pour construire l'image : c'est l'ecart entre la source et l'image qu'on veut contruire.
Les instructions RUN servent a construire l'image, donc les commandes a executer seront inactives apres leur exe.
Pour cette raison, on va privilegier l'ecriture terminal
Possibilite d'ecrire plusieurs commandes en les separant par un ;
L'utilite majeure de RUN est d'installer des fonctionnalites particulieres a l'image

(!)
Attention : ne pas utiliser "RUN yum update -y" seul, a cause du cache Dockerfile (voir page 125)
Si une instruction a deja ete faite sur une machine, elle ne sera pas executee a nouveau lors de la nouvelle construction d'un dockerfile mais lue depuis le cache
On peut ainsi avoir des versions de paquets differents selon la machine sur laquelle on execute le dockerfile

Conclusion :
Toujours s'assurer que les paquets sont a jour avant d'en installer un nouveau
ie : Toujours combiner "yum update -y " avec le "yum install -y Package"

CMD :
Execute une commande au demarrage du conteneur resultant.
Cette instruction ne sera pas jouee lors de la constrution de l'image, mais pendant l'execution du conteneur associe
Seule la derniere instruction CMD du Dockerfile sera jouee. Il ne faut avoir qu'une seule instruction CMD par Dockerfile

Il existe une forme CMD ["param1", "param2"] sans preciser en premier lieu un executable
Elle doit etre combinee avec l'instruction ENTRYPOINT
Utile dans le cas d'une surchage du point d'entree du conteneur sur seulement une partie de commande

ex :
ENTRYPOINT ["/bin/ping", "-c", "5"]
CMD ["localhost"]

Plus simple de surchager l'instruction CMD que ENTRYPOINT :
docker run image_name new_cmd
docker run --entrypoint new_entry image_name

ENTRYPOINT :
Comme CMD, permet d'executer une commande au demarrage du conteneur resultant
Carac identiques a CMD : jouee uniquement demarrage conteneur, seule derniere instruction executee

(!) Attention :
Si instruction ENTRYPOINT format EXE alors instruction CMD (peut importe format) sera rajoute a la fin de l'instruction ENTRYPOINT
Si instruction ENTRYPOINT format TERMINAL alors CMD sera (peut importe format) sera ignoree

EXPOSE :
Decrit les ports que le conteneur expose et sur lesquels il ecoute
Ces ports devront ensuite etre mappe avec des ports de l'hote executant le conteneur pour etre accessibles
On peut exposer pour un protcole uniquement :
EXPOSE 80/TCP

Le mappage du port peut se faire :
Automatiquement : docker run -P
Manuellement :
(!)
- Specifier quels ports doivent etre mappes parmis ceux exposes
- Specifier les ports hotes a utiliser afin de les mapper avec les ports exposes
La precision du port hote est facultative
docker run -p [port_hote:]port_expose
L'option -p est cumulative

Resume :
- Option -P et les ports exposes par EXPOSE seront mappes automatiquement avec des ports dispo
- Option -p et les ports exposes sont specifies manuellement. L'instruction EXPOSE devient alors informative

ADD :
Ajoute un fichier dans l'image. Il ne s'agit pas d'un alias ou d'un raccourci
La ou les sources peuvent etre des fichiers locaux ou distants
Si src est fichier local, il doit etre dispo sur la machine qui construit l'image et par forcement sur celle qui fait docker run
Possibilite de changer l'utilisateur a la copie
Mieux vaut utiliser un curl ou un wget que ADD pour les fichiers distants, car fonctions de dl sont limitees

Le chemin courant de la machine qui construit est donne en parametre de la fonction build
Le chemin courant dans le conteneur est '/' sauf s'il a ete change avec WORKDIR

(!) Attention :
Chaque instruction dans un Dockerfile est executee de maniere a etre independante dans le but de creer des images intermediaires dans le systeme de cache.
A chaque instruction le contexte courant redevient celui par defaut ('/' pour le workdir)

(!) Attention :
Si le fichier copie est une archive .tar locale avec un format de compression reconnu, alors il sera decompresse en dossier

(!) Attention :
Si le destination se termine par un '/', cela veut dire qu'on specifie un dossier et que la source sera ajoutee telle quelle dans ce dossier.
Sinon, c'est un nouveau nom

COPY :
Permet d'ajouter un fichier dans l'image.
La source doit etre un fichier local. Il ne s'agit pas d'un alias ou d'un raccourci
Difference avec ADD :
- La source doit etre un fichier local
- COPY ne decompresse pas automatiquement

(!) Attention :
COPY et ADD permettent d'ajouter plusieurs fichier en une seule fois, cependant, pas recommande afin exploiter cache Docker
Si au moins un fichier source est modifie, l'instruction sera consideree comme changee et sera rejouee (pas utilisation du cache) ainsi que toutes les suivantes

VOLUME :
Permet de creer un point de montage dans l'image.
Il se referera a un emplacement, appele volume, dans l'hote ou dans un autre conteneur.
En bonne pratique, on utilisera une seule instrution volume TERMINAL (pour limiter images intermediaires) avec eventuellement plusieurs volumes
L'option -v emplacement_hote:emplacement_conteneur fait double emploi avec l'instruction VOLUME du conteneur.
L'effet fonctionnel de l'instruction devient ainsi nul, mais elle apporte une meta donne sur le point de montage dans le conteneur.
L'instruction VOLUME est toujours executee a partir de '/' meme si workdir change le chemin courant.
On specifiera toujours '/' pour plus de clarete

6.3 Bonnes pratiques

Generalites :
Format exe pour CMD et ENTRYPOINT
Format terminal pour RUN
Trier les instructions pour optimiser cache :
FROM, ARG, ENV-LABEL, VOLUME, RUN-COPY-WORKDIR, EXPOSE, USER, ONBUILD, CMD-ENTRYPOINT

Pas de sudo

FROM :
Une seule instruction et on precise le tag

RUN :
Maj systematique de l'image et une seule instruction pour tous les packages
ex :
RUN yum update -y && yum install -y \
package1 \
package2 \
package3
Utilisation de WORKDIR plutot que changer chemin courant avec run

CMD et ENTRYPOINT :
Utilisation de ENTRYPOINT en priorite
CMD utilisee si le point d'entree doit etre surcharge partiellement (entry+cmd) ou totalement (uniquement cmd)

EXPOSE :
On l'utilisera pour renseigner clairement les ports qu'utilise le conteneur

ADD/COPY :
Systematiquement COPY au lieu de ADD
Modele terminal car plus simple a lire
Une instruction par fichie a ajouter

VOLUME :
On l'utilisera pour renseigner clairement les points de montage qu'utilise le conteneur
Chemin commencea toujours par un /
Une seule instruction VOLUME

ENV/LABEL/ARG :
On regroupera les variables d'env en une seule instruction. Idem pour les labels
On preferera surcharger l'env value PATH plutot que de specifier a chaque fois le chemin absolu
Instruction ARG toujours devant ENV et LABEL
Si env value peut etre surchagee lors de la construction d'une image, on utilisera conjointement ARG et ENV selon modele :
ARG variable
ENV variable ${variable:-valeurParDefaut}

7. Docker avance

7.1. ENV
Permet crer ou maj valeur d'environnement afin des les utiliser lors de la construction de l'image OU dans les conteneurs associes
Les variables d'env sont disponibles dans toute la descendance de l'image : un conteneur a acces :
- Aux variables d'env decrites dans son Dockerfile
- Aux variables d'env decrites dans le Dockerfile de l'image source

Si plusieurs variables d'env doivent etre crees, on prefere la forme "ENV key1=value1 key2=value2 ..." plutot que multiples "ENV key=value" afin de ne creer qu'une seule couche de cache image
Penser a utiliser guillements ou echapper les espaces

Utilisation de ENV typique pour surcharger le PATH

Possible de surcharger variable d'env au demarrage conteneur :
docker run --env key=value
--env est cumulative

7.2 LABEL

Permet d'ajouter des metadonnes a l'image
Les valeurs doivent etre encapsulees par des guillemets
On peut lister les labels avec docker inspect
docker inspect --format='{{json .Config.Labels}}' image_to_inspect
Possible d'ajouter de l'info a la construction avec docker build --label key=value

7.3 Parameter le BUILD
Il s'agit d'influencer la maniere dont l'image va etre construite

WORKDIR :
Changer le cheming courant.
S'applique a toute instruciton qui suit.

(!)
Attention :
L'instruction change le chemin courant dans l'image : le chemin du conteneur demarre sera celui de la derniere instruction WORKDIR
Le chemin de l'instruction WORKDIR sera toujours specifie en absolu

(!)
WORKDIR permet l'utilisation de variables d'env creer par ENV au sein du meme Dockerfile.
Une env value provenant d'une image source ou native d'une systeme ne pourra par etre utilisee

ENV cheminCourant /tmp
WORKDIR $cheminCourant/$unFichier

Aura pour resultat un workdir a /tmp/$unFichier ($unFichier non substitue car n'existe pas dans le Dockerfile)

ARG :
Permet de definir des variables (arguments) qui sont passes comme parametres lors de la construction d'une image.
On devra alors utiliser "docker build --build-arg name=value"

ARG <name>[=<defaultValue>]
default value est optionnel (difference avec les env du coup)

(!)
Attention : Si une valeur contient des espaces, elle doit etre encapsulee par des ""

Utilisation d'un argument :
${name:-val_par_defaut} OU $name

Possibilite d'utiliser un argumet uniquement s'il a ete defini par ARG avant
Ne pas passer d'infos sensibles avec --build-arg
Les arguments donnes avec --build-arg doivent imperativement avoir ete definis dans le Dockerfile
La portee des variables definies par ARG ne s'etendd pas au conteneur

(!)
Attention : ENV prime sur ARG :
- ENV place avant ARG : ARG sera ignore
- ENV place apres ARG : ARG valable jusqu'a ENV

Pour agir sur image et conteneur associes : ENV
Pour agir uniquement sur instructions de constructions : ARG

Surchage :
- Pour ARG, la surcharge se fait a la construction de l'image: docker build
- Pour ENV, la surchage se fait au demarrage du conteneur : docker run
Si on surchage une variable d'env uniquement au demarrage, on peut avoir val differente a la construction et a l'exe
Il faut donc documenter l'image, notamment en specifiant les valeurs d'env qui peuvent etre surchargees au demarrage

Bonne pratique :
ARG value
ENV value ${value:-defaultValue}

(!)
Attention :
Une variable d'env qui ne peut pas etre surchargee lors de la constructionde l'image (via Bonne pratique au dessus) ne doit JAMAIS etre utilisee par des instruction de construction de l'image

ONBUILD :
Permet de definir des instructions qui seront executees uniquement lors de la construction des images enfants directs
Les instructions ONBUILD seront executees directement apres l'instruction FROM
Utilisable avec RUN, ADD, COPY, USER et ARG)
Il convient de tagguer avec onbuild toute image qui a une ou plusieurs instructions ONBUILD

A la lecture d'une instruction ONBUILD, le constructeur Docker va creer une metadonnee qu'il placera dans le manifeste de l'image au niveau de la clef OnBuild
On pourra les chercher avec docker inspect
Si une instruction ONBUILD echoue, c'est l'instruction FROM qui echouera

7.5 Modifier le contexte system au cours du BUILD
Une ima

SHELL :
