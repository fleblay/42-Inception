Avant-Propos :

Conteneur : virtualisation de niveau systeme d'exploitation
Hyperviseur/VM : virtualisation au niveau materiel

Contrairement a une VM, un conteneur n'embarque pas d'OS complet

1. Conteneurs et le cas Docker
1.1 La conteneurisation

Dans une architecture a base de conteneurs :
- Le contenu du conteneur, cad le code et ses dependances (jusqu'a l'OS) est de la responsabilite du dev
- La gestion du conteneur et les dependances avec l'infra sont de la responsabilite de l'exploitant

Virtualisation materielle : chaque logiciel se trouve dans un sandox
- Poids d'une VM important
- Elle ne laisse pas a l'exploitant la possibilite de choisir librement les caracteristiques comme le stockage ou le nombre de CPU...

Architecture a base de conteneur : compromis
- Isolation presente
- Conteneur s'appuie sur le kernel de l'OS hote, il est donc leger. Un hote peut executer beaucoup plus de conteneurs que d'equivalent VM

Eventuellement, conteneurs dans une VM permet de se premunir des MAJ de l'OS hote qui pourraient impacter les conteneurs.
Il existe des projets visant a fournir des OS hotes minimaux qui se focalisent uniquement sur les problemes d'infra. Cela limite les risques d'attaques et de bug.

Docker apporte 2 avantages aux solutions a base de conteneurs :
- Possibilite de decrire formellement comment construire le conteneur
- Format d'image standardisee

1.2 Les fondations : Linux, cgroups et namespaces

Docker est une solution open-source de conteneur Linux.
Initialement, s'appuie sur LXC (Linux Containers) pour implementation, puis libcontainer (bibli bas niveau) puis runC, standard de l'OCI (Open Container Initiative).
Docker aujourd'hui construit au-dessus de containerd qui s'appuie sur runC.

Contaitneurs sont une techno liee au noyau Linux (Linux Kernel) et certains de ses services sont orchestree par containerd.

Depuis 2016, possibilite d'executer des conteneurs natif sous windows grace au portage de runC sur le noyau Windows.

Pour executer des conteneurs Linux sous Windows, on fait tourner une VM Hyper-V avec OS LinuxKit LCOW (Linux Containers On Windows) et le conteneur a l'interieur.
Idem sous Mac, on fait tourner une VM basee sur l'Hypervisor Framework Apple : Xhyve

CGroups : (Control Groups)
Permet de partitionner les ressources d'un hote pour controler la consommation des ressources process par process
Introduit la notion de controleur avec pour objectif de controler acces a une ressource pour une hierarchie de process

Namespaces : Permet de faire en sorte que les processus ne voient pas les ressources utilisees par d'autres.
Version amelioree de chroot : Le process aura l'impression d'etre a la racine du systeme. Namespace etend le concept a d'autres ressources (Com interprocess, Terminaux resaux, point de montage systeme etc...)

(!)
Un conteneur est un systeme de fichier sur lequel s'executent des process (de preference 1 par conteneur) de facon :
- contrainte : grace a cgroups qui specifie les limites en termes de ressources
- isolee : grace a namespaces qui fait en sorte que les conteneurs ne se voient pas les uns les autres

1.3 Les apports de Docker : Structure en couches, images, volumes et registery

Docker optimise la taille des conteneurs :
Construire un conteneur a la main : Operation fastidieuse et probleme de distribution et reutilisation
(!)
Par exemple stocker les fichiers specifiques au conteneur qui ne font pas partie de l'OS dans un repertoire
Apport essentiel de Docker : les images, qui sont une maniere de conditionner le contenu d'un conteneur en blocs reutilisables et echangeables.

Possible grace a l'union file system :
Chaque couche surcharge la precedente en y apportant de modifications et ajouts.
On a plusieurs couches successives qui sont autant de blocs reutilisables.

Docker Hub et registry :
Le registry est l'annuaire et le centre de stockage des images reutilisables.
Docker Hub est sa principale instanciation publique
Le registry Docker herberge les images de base de principaux systemes d'exploitation (Ubuntu, Debian ...) et de nombreux logiciels courants (bdd, serveurs d'appli etc...)
Le registry peut etre au choix :
- Le lieu de stockage d'images crees sur un hote par un dev (docker push)
- La source d'images a installer sur un ou plusieurs hotes (docker pull)
(!)
Certaines images peuvent rester privees et ne pas etre publiees sur un registry : ces images restent au niveau du cache de l'hote

Reutilisation des images de 2 manieres :
- A l'echelle d'un hote, via un cache local
- A l'echelle d'un registry, en offrant un moyen de partage d'images

Copy on write, persistance des volumes :

A un moment, l'image d'un conteneur va etre mise en route (execution de process qui consomment de la memoire, ecrire des donnees etc...)
Les donnes sont produites dans une couche au dessus de toutes les autres, la container layer.
Cette couche est modifiable contrairement aux couches d'image qui ne le sont pas.
Le Copy On Write : Lorsqu'une modification est demandee sur un element de l'image, le fichier original est copie te la nouvelle version surchage l'originale.
Le COW n'est utilise que lors d'une modification, sinon c'est la version originale de l'image qui est utilisee.
La couche du conteneur ne contient que le differentiel par rapport a l'image.
(!)
La maniere de gerer le COW et l'union des couches depend du storage driver. Docker est livre avec un driver par defaut adapte a l'OS.

Quand le conteneur s'arrete, la container layer est perdue. Pour conserver des donnees -> volumes.
Les volumes sont des espaces de donnees qui court-circuitent le system d'union file. Ils sont modifies directement et les donnees qui y sont inscrites survivent a l'arret du conteneur.
Ce sont des systemes de fichiers montes dans le conteneur :
(!)
- Sur un espace disque de l'hote gere par Docker
- Sur un repertoire de l'hote directement monte dans le conteneur

1.4 Les outils de l'ecosysteme des conteneurs :

Les moteurs :
Le moteur d'execution de conteneur (par exemple Docker Engine) offre des fonctionnalites de plus haut niveau par rappoort a Cgroups et Namespace :
- une CLI
- des API
- Capacite de nommer, decouvrir et gerer le cycle de vie des conteneurs
- La capacitee de creer des conteneurs a partir d'images ou de modeles

Il existe d'autres type de moteur que le Docker Engine :
- LXC sur lequel Docker s'appuyait avant la libcontainer
- Containerd, basee sur runC (composant de bas niveau destine a s'integrer dans des moteurs de plus haut niveau)
- Podman

Le standard OCI (Open Container Initiative) pour les images ou CRI (Container Runtime Interface) pour Kubernetes impose un standard qui assure portabilite entre les environnements et les moteurs.
Docker reste l'outil de reference pour les dev, mais n'est plus le leader cote serveur.

OS specialises :
Les conteneurs reutilisent le noyau de l'OS de l'hote sur lequel ils tournent.
Les containers OS sont des OS simplifies, plus performants et moins exposes aux risques de securite ou d'instabilite
Exemples :
- Fedora CoreOS pour Redhat
- LinuxKit qui permet de creer des distro Linux compactes (dont LCOW qu'utilise window au sein de sont hyper-v)
etc...

Pour Windows :
- Windows Server Core pour les hotes qui n'executent que des machines virtuelles ou des conteneurs
- Windows Nano Server pour l'image de base de conteneurs Windows

Outils d'orchestration :
Les bonnes pratiques en matiere d'architecture consistent a distribuer les processus dans plusieurs conteneurs.
(!)
Il faudra donc les associer, c'est la composition :
- Definir l'ordre de demarrage.
- Definier les systemes de fichier persistants (volumes)
- Definir les liens reseau que les conteneurs vont entretenir entre eux
On peut demarrer les conteneurs a la main avec un script qui execute des docker run, mais on ne peut pas distribuer la charge dans ce cas.
Il faut que le composition s'effectue en collaboration avec les outils de clustering reseau qui vont abolir les frontieres entre les differents hotes.
C'est l'orchestration : Composition + clustering

DCOS : Data Center OS
Solution de haut niveau pour orchestration. Le standard est Kubernetes.

2. Orchestration de conteneurs.
2.1 Automatiser la gestion de l'infra : du IaaS au CaaS

IaaS : Virtualisation d'infra
Les solutions IaaS offrent aux appli conditionnes sous forme d'images de machines virtuelles des services d'infrastructure : Puissance de calcul, stockage, services reseau, securitee.
Les solutions IaaS vont detecter les failles materielles et s'assurer que l'environnement d'exe est toujours actif.

En mode IaaS, le dev doit specifier ses besoin en matiere d'environnement d'exe :
Dialogue pousse entre le dev et l'exploitant.
Le dev specifie ses besoins (version java, bdd, server d'appli...) et l'exploitant les interprete.
Phase sensible et complexe.

Apres avoir produit et conditonne sont code (build et packaging) le dev donne son paquet logiciel a l'exploitant.
Il doit rester coherent avec l'archi de la solution.
La gestion de la solution de deploiement est la responsabilite de l'exploitant.

Iaas:
Apporte solution sur preparation environnement applicatif :
- Automatisation du provisionnement de l'infra. Tout se fait par config, si capactite dispo (Pas besoin pour client d'acheter des serveurs etc...)
- Maniere simple de monter en charge si l'appli le permet : On redimensionne l'environnement en ajoutant CPU, RAM etc...

Ne donne pas de solution pour :
- Deploiement des applis (Installation et mise en route une fois la VM cree)
- Description formelle des caracteristiques d'evolutivite et de resilience de l'appli a faire par le dev et l'execution en prod.

Apport du deploiement en CaaS :
Les phases de preparation de l'env et le deploiement sont indistinctes :
- L'image de conteneur inclue l'environnement d'exe (runtime) en meme temps que le code.
- Si usage Docker, via image, le paquet logiciel est exactement ce qui va etre deploye.
Il n'y a pas de retraitement de l'image par une solution tierce.
Comme un conteneur physique, l'exploitant est comme un transporteur : il choisit la maniere dont le conteneur va etre execute sans l'alterer.

De plus, les sulitions CaaS associent au deploiement des regles de gestion (sous forme de fichier YAML ou JSON).
Cette config va specifier de facon formelle les carac non fonctionnelles de l'archi : nombre d'instance, liens en conteneurs, regles de montee en charge et repartition...

Une appli doit etre developpee des le debut pour etre container-ready en revanche

Carac communes des solutions CaaS :
- Moteur de de conteneurs : Conteneurd en general (ou Docker Engine)
- Fonctions de clustering et d'orchestration
- Principe de gestion automatisee de l'infra (homeostasie)

Regulation homeostatique : toutes les solutions CaaS ont ces composants en commun avec pour but :
- Surveiller etat du systeme
- Detecter les ecarts par rapport au regles de gestion programmees
- Prendre des mesures pour ramener l'equilibre
- Prevenir l'exploitant en cas d'echec.

System de regulation:
- Controleur qui analyse l'etat de l'infra via les donnees remontees par les agents. Il donne des ordres aux agents.
- Agents qui collectent des infos sur l'etat des noeuds (le feedback) et servent de relais au controleur pour executer les actions correctrices.
- Une interface d'entree de regles de gestion : une CLI generalement (entree directe ou fichier conf)

L'exploitant programme les regles de gestion (sur la base de proposition du dev)
Ces regles de gestion persistent pendant tout le cycle de l'appli.

DCOS :
Les conteneurs et les Caas sont au coeur des DCOS mais n'en sont qu'une compostante.
Les DCOS doivent etre capables de gerer differents types de ressources et pas juste de conteneurs

2.2 Les solutions CaaS

Kubernetes :
Projet Open Source initie par Google.
Pour info, la plupart des technos de base des conteneurs (Cgroups et Namespaces) ont ete elaborees par des ingenieurs Google.
Kubernetes gere par la Linux Foundation

Archi Kubernetes :
- Controleur central : Kubernetes Control Plane. Peut stocker sa conf dans un cluster etcd.
- Des nodes : Hebergent les agents Kubernetes, les kubelets, et les conteneurs organises en pod.
Les kubelets sont les agents qui controlent les conteneurs organises en pod. Ils surveillent leur etat en utilisant cAdvisor qui est en lien avec le moteur de conteneur.
Le node contient egalement un kube-proxy : proxy repartiteur de charge (load balancer) pour les services offerst par les pods, uniquement au sein d'un cluster Kubernetes.

Le Kubernet Controle Pane subdivise en :
- Serveur API, utilise par Kubctl, la CLI qui permet de piloter les composants de l'archi
- Le Scheduler : pour provisionner de nouveaux pools de conteneurs sur les noeuds
- Le Controller Manager : Execute les boucles de controle

Nodes, pods et conteneurs :
Un node correspond en general a un hote physique ou virtuel
Un pod est un groupe de conteneurs toujours colocalises et provisionnes ensembles. Ils sont lies les uns aux autres et offrent une instance de micro-service
(!)
Tous les conteneurs d'un pod se trouvent dans une meme machine logique :
- Partagent les meme volumes
- Peuvent interagir en utilisant le nom de domaine localhost ce qui simplifie les interacitons
Chaque pod est associe a une IP unique. L'espace d'adressage a l'interieur d'un cluster est plat (pod peuvent se parler sans recours a la NAT)

Un service est un ensemble de pods associes a des regles d'acces, de replication et de repartition de charges specifiques
La notion de service interne au cluster : le kube-proxy permet a un pod front-end de trouver un pod back-end en utilisant des regles de repartition de charge.
En revanche, si un utilisateur exterieur veut acceder au front-end, on utilise un external load-balancer qui sera associe a une IP publique et offrira chiffrement SSl, load balancing niveau 7, affinite session etc...
L'implementation open source de l'external load balancer est basee sur NGINX

Toute solution d'orchestration de conteneur se doit de supporter Kubernetes

Modele Docker Entreprise : echec commercial
- Docker Compose :  encore beaucoup utilise par les dev comme outils de composition de conteneurs
- Docker Classic Swarm : Offre de clustering concurrente de Kubernetes. Transformait plusieurs machines en 1 seul hote.
- Docker Trusted Registry : Stockage des images conteneurs
- Docker UCP (Universal Control Pane) : Centre de control Datacenter

Une des strategies de swarm etait spread : lors de la creation d'un certain nombre de conteneurs, la strategie s'assurait que les creations etaient distribuees uniformement sur chaque noeud d'un cluster

DCOS :
Apache Mesos est a l'origine.
Concept de Framework, qui permet de se brancher sur diverses solution de controle, dont Kub.
Architecture : des mesos master (eventuellement dupliques, comme des master nodes) et des mesos slaves qui hebergent les agents emis depuis le master et fournir des infos
Mesos peut utiliser d'autres techo de deploiement et d'exe.

Openshift de Red Hat : Solution de reference de Kubernetes pour une installation privee
Contruite en integrant les produits CoreOS

Nomad de HashiCorp :
Etend la gestion de process distribues au dela des conteneur (a la maniere de Mesos)
Permet transition entre ancien monde et celui des conteneurs et du multi-conteneur mono-hote vers le multi-multi

Les 3 plus grosses offres de cloud container service :
- Google Kubernetes Engine
- Azure Kubernets Service
- Amazon ECS

Ansible, Chef, Puppet : lien avec Docker et Caas

Les solutions CaaS sont nouveaute sur marche gestion d'infra. La plupart des service IT doivent composer avec un existant qui a large panel de techno.
Le but de ces solutions est d'unifier la gestion de configuration d'infra informatiques.
Elle se basent sur un DSL (Domain Specific Language) pour declarer la conf cible a atteindre.
Ces solutions visent a remplacer les nombreux scripts shell par une bibliotheque d'actions standardisees.
Cela permet de s'abstraire des evolutions techno. et surtout de simplifier l'elaboration de procedures de conf independantes des environnements.

Exemple : Ansible de Red Hat
Uniquement besoin du logiciel sur la machine de controle, pas besoin d'agents sur les machines qui doivent etre config : uniquement SSH et python
Playbook : descripteurs de config. Decrit l'etat souhaite pour un ou plusieurs hotes
Inventory : liste des hotes cibles, qui peuvent etre machines virtuelles
Les hotes cibles sont organises en groupes, ce qui permet de lancer des actions de masse

Playbook : par exemple au format YAML. C'est une description d'un etat souhaite, pas une liste de commandes.
Ansible collecte, avant d'effectuer des actions, des infos relatives a l'environnement de la machine (les facts)

Lien avec Docker et les solutions CaaS :
Comme les Caas, Ansible fonctionne en comparant une etat actuel avec un etat cible.
La difference est que la comparaison d'etat n'est pas permanente : on veut juste configurer un systeme et non pas le gerer en temps reel.
Les solutions CaaS et les gestion de conf type Ansible sont donc complementaires.
Par exemple Ansible va permettre installation et config des agents CaaS (ex: Kublets) sur les hotes
Ansible dispose d'un playbook docker par ex.
Ansible va gerer cycle de vie du conteneur, depuis chargement image jusqu'a creation et demarrage
